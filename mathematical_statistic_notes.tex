\documentclass[%
	11pt,
	a4paper,
	utf8,
	%twocolumn
		]{article}	

\usepackage{style_packages/podvoyskiy_article_extended}


\begin{document}
\title{Классические и продвинутые темы теории вероятностей и математической статистики}

\author{\itshape Подвойский А.О.}

\date{}
\maketitle

\thispagestyle{fancy}

Здесь приводятся заметки по некоторым вопросам, касающимся машинного обучения, анализа данных, программирования на языках \texttt{Python}, \texttt{R} и прочим сопряженным вопросам так или иначе, затрагивающим работу с данными.


\shorttableofcontents{Краткое содержание}{1}


\tableofcontents

\section{Эмпирическая и теоретическая функции распределения}

Построим по выборке $ X_1, X_2, \dots, X_n $ случайную ступенчатую функцию $ \hat{F}_n(x) $, возрастающую скачками величины $ 1/n $ в точках $ X_{(i)} $ ($ i $-ая порядковая статистика). Эта функция называется \emph{эмпирической функцией распределения}. Чтобы задать значения в точках разрывов, формально определим ее так, чтобы она была непрерывна справа
\begin{align*}
	\hat{F}_n(x) = \dfrac{1}{n} \sum_{i = 1}^{n} I_{ \{X_{(i)} \leqslant x\} } = \dfrac{1}{n} \sum_{i = 1}^{n} I_{\{X_i \leqslant x\}}.
\end{align*}

В отличие от эмпирической функции распределения выборки, интегральную функцию $ F(x) $ распределения генеральной совокупности называют \emph{теоретической функцией распределения}.

Различие между эмпирической и теоретической функциями распределения $ F(x) $ состоит в том, что {теоретическая функция} определяет \emph{вероятность} события $ X_i \leqslant x $, а эмпирическая функция $ \hat{F}_n(x) $ определяет \emph{относительную частоту} этого события. Из теоремы Бернулли следует, что относительная частота события $ X_i \leqslant x $, т.е. $ \hat{F}_n(x) $ стремится по вероятности к вероятности $ F(x) $ этого события. Другими словами числа $ \hat{F}_n(x) $ и $ F(x) $ мало отличаются одно от другого \cite[191]{gmurman:1972}.

\section{Доверительные интервалы}

\emph{Доверительный интервал} -- интервал, покрывающий неизвестный скалярный параметр $ \theta $ с заданной \emph{доверительной вероятностью} $ (1 - \alpha) $

\begin{align*}
	P(\hat{\theta}_1(X_1, X_2, \dots, X_n) < \theta < \hat{\theta}_2(X_1, X_2, \dots, X_n)) \geqslant 1 - \alpha,
\end{align*}
где $ \hat{\theta}_{1,2} $ -- нижняя и верхняя граница доверительного интервала (\emph{случайные величины}), $ \alpha $ -- уровень значимости (она же вероятность ошибки первого рода).

Наиболее часто уровень значимости принимают равным 0.05 или 0.01. Если, например, принят уровень значимости равный 0.05, то означает, что в пяти случаях из ста мы рискуем допустить ошибку первого рода (отвергнуть правильную гипотезу) \cite[284]{gmurman:1972}.

\emph{Границы доверительного интервала} являются \emph{случайными величинами} -- функциями от выборки (или другими словами границы доверительного интервала являются \emph{статистиками}) -- поэтому правильнее говорить не о вероятности попадания $ \theta $ в доверительный интервал, а о вероятности того, что доверительный интервал \underline{покроет} неизвестный параметр $ \theta $ \cite[216]{gmurman:1972}.

\paragraph{Интервалы в нормальной модели} Допустим, что элементы выборки $ X_i $ распределены по закону $ \mathcal{N}(\theta, \sigma^2) $, причем параметр масштаба $ \sigma $ известен, а параметр сдвига $ \theta $ -- нет. Эту модель часто применяют к данным, полученным при независимых измерениях некоторой величины $ \theta $ с помощью прибора (или метода), имеющего известную среднюю погрешность (стандартную ошибку) $ \sigma $.

Если случайная величина $ X $ распределена нормально $ \mathcal{N}(\theta, \sigma) $, то выборочная средняя $ \bar{X} $, найденная по независимым наблюдениям, также распределена нормально. Параметры распределения таковы
\begin{align*}
	\mathbf{E}(\bar{X}) = \theta, \sqrt{\mathbf{D}(\bar{X})} = \dfrac{\sigma}{\sqrt{n}} \quad \to \quad \bar{X} \sim \mathcal{N}(\theta, \sigma^2/n).
\end{align*}

Для центрированной и нормированной случайной величины $ \sqrt{n}(\bar{X} - \theta)/\sigma \sim \mathcal{N}(0,1) $ в качестве границ интервала с доверительной вероятности $ 1 - \alpha $ можно взять
\begin{align*}
	\hat{\theta}_1 = \bar{X} - \sigma/\sqrt{n} \, x_{1 - \alpha/2}, \quad \hat{\theta}_2 = \bar{X} + \sigma/\sqrt{n} \, x_{1 - \alpha/2}.
\end{align*}

Таким образом, с вероятностью 0.95 истинное значение параметра сдвига $ \theta $ находится в интервале $ \bar{X} \pm 1.96\, \sigma/\sqrt{n} \approx \bar{X} \pm 2\, \sigma/\sqrt{n} $ (правило двух сигм) \cite[147]{lagutin:2009}.

На практике, если значение $ \sigma $ неизвестно, то его заменяют на \emph{состоятельную оценку} $ \hat{\sigma} = S $, где $ S^2 = \dfrac{1}{2}\sum (X_i - \hat{X})^2 $.

Оценка $ \hat{\theta} $ параметра $ \theta $ называется \emph{состоятельной}, если для всех $ \theta \in \Theta $ последовательность
\begin{align*}
	\hat{\theta}_n = \hat{\theta}(X_1, \dots, X_n) \xrightarrow{\mathbf{P}} \theta, \quad n \to \infty.
\end{align*}

Здесь $ \xrightarrow{\mathbf{P}} $ обозначает \emph{сходимость по вероятности}
\begin{align*}
	\forall \varepsilon > 0, \,\, \mathbf{P}( | \hat{\theta} - \theta | > \varepsilon ) \to 0, \quad n \to \infty.
\end{align*}

\emph{Состоятельность} оценки (а точнее -- последовательности оценок $ \{\hat{\theta}_n\} $) означает концентрацию вероятностной массы около истинного значения параметра $ \theta $ с ростом размера выборки $ n $ \cite[75]{lagutin:2009}.

\section{Центральная предельная теорема}

Пусть $ X_1,\dots, X_n $ -- независимые одинаково распределенные случайные величины. Положим $ S_n = X_1 + X_2 + \dots + X_n $.

Если $ 0 < \sigma^2 = \mathbf{D}X_1 < \infty $, то
\begin{align*}
	S^{*}_n = \dfrac{ S_n - \mathbf{E}S_n }{ \sqrt{\mathbf{D} S_n} } = \dfrac{S_n - \mu n}{\sigma \sqrt{n}} \xrightarrow{d} Z, \quad n \to \infty,
\end{align*}
где $ Z $ -- стандартная нормальная случайная величина, $ Z \sim \mathcal{N}(0, 1) $.

\paragraph{Пример} Пусть случайные величины $ Z_1, \dots, Z_k $ распределены по закону $ \mathcal{N}(0, 1) $ и независимы. Тогда распределение случайной величины $ R^2_k = Z_1^2 + \dots + Z_k^2 $ называют распределением $ \chi^2 $ c $ k $ степенями свободы (кратко $ R_k^2 \sim \chi_k^2 $).

Отметим, что каждое слагаемое имеет гамма-распределение с параметрами $ \alpha = \lambda = 1/2 $, т.е. $ Z_i^2 \sim \Gamma(1/2, 1/2) $. 

Поскольку $ R_k^2 $ -- это сумма независимых и одинакового распределенных случайных величин $ Z_i^2 $, то согласно \emph{центральной предельной теореме} имеет место \emph{сходимость по распределению}
\begin{align*}
	(R_k^2 - \mathbf{E}R_k^2) / \sqrt{\mathbf{D}R_k^2} = (R_k^2 - k)/\sqrt{2 k} \xrightarrow{d} Z \sim \mathcal{N}(0, 1), \quad k \to \infty.
\end{align*}

Нормальное приближение является довольно точным уже при $ k > 30 $.



% Источники в "Газовой промышленности" нумеруются по мере упоминания 
\begin{thebibliography}{99}\addcontentsline{toc}{section}{Список литературы}
	\bibitem{gmurman:1972}{\emph{Гмурман В.Е.} Теория вероятностей и математическая статистика. -- М.: Высшая школа, 1972.~-- 368~с. }
	
	\bibitem{lagutin:2009}{\emph{Лагутин М.Б.} Наглядная математическая статистика. -- М.: БИНОМ, 2009.~-- 472~с. }
\end{thebibliography}

\end{document}
